<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.46" />
  <meta name="author" content="Samir Lamara">

  
  
  
  
    
  
  <meta name="description" content="Predict the survival of a test subset of passengers using machine learning">

  
  <link rel="alternate" hreflang="en-us" href="https://slamara.github.io/project/titanic/">

  


  

  
  
  
  <meta name="theme-color" content="#EF525B">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/sunburst.min.css" crossorigin="anonymous">
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-123444635-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="https://slamara.github.io/index.xml" type="application/rss+xml" title="Samir Lamara">
  <link rel="feed" href="https://slamara.github.io/index.xml" type="application/rss+xml" title="Samir Lamara">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://slamara.github.io/project/titanic/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Samir Lamara">
  <meta property="og:url" content="https://slamara.github.io/project/titanic/">
  <meta property="og:title" content="Titanic: Machine Learning from Disaster- A Kaggle Competition | Samir Lamara">
  <meta property="og:description" content="Predict the survival of a test subset of passengers using machine learning"><meta property="og:image" content="https://slamara.github.io/img/titanic.jpg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-08-08T17:42:32&#43;02:00">
  
  <meta property="article:modified_time" content="2018-08-08T17:42:32&#43;02:00">
  

  

  

  <title>Titanic: Machine Learning from Disaster- A Kaggle Competition | Samir Lamara</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Samir Lamara</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/files/cv.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article article-project" itemscope itemtype="http://schema.org/Article">

  
<div class="article-header">
  
  
    <img src="/img/titanic.jpg" class="article-banner" itemprop="image">
  

  
</div>



  <div class="article-container">

    <div class="pub-title">
      <h1 itemprop="name">Titanic: Machine Learning from Disaster- A Kaggle Competition</h1>
      <span class="pub-authors" itemprop="author">&nbsp;</span>
      <span class="pull-right">
        
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Titanic%3a%20Machine%20Learning%20from%20Disaster-%20A%20Kaggle%20Competition&amp;url=https%3a%2f%2fslamara.github.io%2fproject%2ftitanic%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fslamara.github.io%2fproject%2ftitanic%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fslamara.github.io%2fproject%2ftitanic%2f&amp;title=Titanic%3a%20Machine%20Learning%20from%20Disaster-%20A%20Kaggle%20Competition"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fslamara.github.io%2fproject%2ftitanic%2f&amp;title=Titanic%3a%20Machine%20Learning%20from%20Disaster-%20A%20Kaggle%20Competition"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Titanic%3a%20Machine%20Learning%20from%20Disaster-%20A%20Kaggle%20Competition&amp;body=https%3a%2f%2fslamara.github.io%2fproject%2ftitanic%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


      </span>
    </div>

    

    <div class="article-style" itemprop="articleBody">
      <div id="overview" class="section level3">
<h3>Overview</h3>
<p>The Titanic left the port of Queensland (now Cobh), Ireland on April 11, 1912 with 2224 passengers <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. On early morning of Monday, 15 April 1912, sank the “unsinkable” after a collision with an iceberg dragging more than 2/3 of the passengers down to the bottom of the Atlantic Ocean.</p>
<p>Due to the insufficient number of means of survival, the possibility to get in lifeboats would have obeyed to some kind of considerations: from the ethical “women and children first” to the more practical proximity to the Upper Deck which is itself related to the cabin class and thus to the socio-economic class of each passenger (see <a href="https://rmstitanic1912.weebly.com/the-levels-of-the-titanic.html">here</a> the different levels of the Titanic).</p>
<p>Based on these considerations, the purpose of this project is to predict the survival of a test subset of passengers using machine learning. To this intent, I “dive” first into the training dataset provided by <a href="https://www.kaggle.com/c/titanic">kaggle.com</a> to identify and engineer the most important predictors.</p>
</div>
<div id="read-data" class="section level3">
<h3>Read data</h3>
<pre class="r"><code>library(ggplot2)
library(Amelia)
library(gridExtra)
library(caret)</code></pre>
<pre class="r"><code>trainVarTypes &lt;- c(&quot;integer&quot;, &quot;factor&quot;, &quot;factor&quot;, &quot;character&quot;, &quot;factor&quot;, &quot;numeric&quot;, 
                   &quot;integer&quot;, &quot;integer&quot;, &quot;character&quot;, &quot;numeric&quot;, &quot;character&quot;, &quot;factor&quot;) 
# for Resp. PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked

testVarTypes &lt;- trainVarTypes[-2]

train &lt;- read.csv(&quot;./titanic/train.csv&quot;, colClasses = trainVarTypes, na.strings = c(&quot;NA&quot;, &quot;&quot;))
test &lt;- read.csv(&quot;./titanic/test.csv&quot;, colClasses = testVarTypes, na.strings = c(&quot;NA&quot;, &quot;&quot;))

train$Survived &lt;- factor(train$Survived, levels = c(0,1), labels = c(&quot;no&quot;, &quot;yes&quot;))</code></pre>
</div>
<div id="preliminary-data-analysis" class="section level3">
<h3>Preliminary data analysis</h3>
<p>The train dataset consists in a subset of 891 observations of 11 variables describing each passenger listed in. According to each variable we can know: whether the passenger survived or not (yes/no), his/her class on board (1st, 2nd or 3rd class), name (including the title), sex (female/male), Age, ticket number, fare, cabin number, and where he/her embarked.</p>
<p>Adding to that, the variables SibSp and Parch represent respectively the number of siblings and spouses, and the number of parents and children. Both variables indicate implicitly whether a passenger has family members on board and how many are they. (more details can be found <a href="https://www.kaggle.com/c/titanic/data">here</a>.</p>
<pre class="r"><code>str(train)</code></pre>
<pre><code>## &#39;data.frame&#39;:    891 obs. of  12 variables:
##  $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Survived   : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 2 2 2 1 1 1 1 2 2 ...
##  $ Pclass     : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 3 1 3 1 3 3 1 3 3 2 ...
##  $ Name       : chr  &quot;Braund, Mr. Owen Harris&quot; &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot; &quot;Heikkinen, Miss. Laina&quot; &quot;Futrelle, Mrs. Jacques Heath (Lily May Peel)&quot; ...
##  $ Sex        : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 1 2 2 2 2 1 1 ...
##  $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...
##  $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...
##  $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...
##  $ Ticket     : chr  &quot;A/5 21171&quot; &quot;PC 17599&quot; &quot;STON/O2. 3101282&quot; &quot;113803&quot; ...
##  $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...
##  $ Cabin      : chr  NA &quot;C85&quot; NA &quot;C123&quot; ...
##  $ Embarked   : Factor w/ 3 levels &quot;C&quot;,&quot;Q&quot;,&quot;S&quot;: 3 1 3 3 3 2 3 3 3 1 ...</code></pre>
<pre class="r"><code>head(train, n = 4)</code></pre>
<pre><code>##   PassengerId Survived Pclass
## 1           1       no      3
## 2           2      yes      1
## 3           3      yes      3
## 4           4      yes      1
##                                                  Name    Sex Age SibSp
## 1                             Braund, Mr. Owen Harris   male  22     1
## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female  38     1
## 3                              Heikkinen, Miss. Laina female  26     0
## 4        Futrelle, Mrs. Jacques Heath (Lily May Peel) female  35     1
##   Parch           Ticket    Fare Cabin Embarked
## 1     0        A/5 21171  7.2500  &lt;NA&gt;        S
## 2     0         PC 17599 71.2833   C85        C
## 3     0 STON/O2. 3101282  7.9250  &lt;NA&gt;        S
## 4     0           113803 53.1000  C123        S</code></pre>
<pre class="r"><code>summary(train)</code></pre>
<pre><code>##   PassengerId    Survived  Pclass      Name               Sex     
##  Min.   :  1.0   no :549   1:216   Length:891         female:314  
##  1st Qu.:223.5   yes:342   2:184   Class :character   male  :577  
##  Median :446.0             3:491   Mode  :character               
##  Mean   :446.0                                                    
##  3rd Qu.:668.5                                                    
##  Max.   :891.0                                                    
##                                                                   
##       Age            SibSp           Parch           Ticket         
##  Min.   : 0.42   Min.   :0.000   Min.   :0.0000   Length:891        
##  1st Qu.:20.12   1st Qu.:0.000   1st Qu.:0.0000   Class :character  
##  Median :28.00   Median :0.000   Median :0.0000   Mode  :character  
##  Mean   :29.70   Mean   :0.523   Mean   :0.3816                     
##  3rd Qu.:38.00   3rd Qu.:1.000   3rd Qu.:0.0000                     
##  Max.   :80.00   Max.   :8.000   Max.   :6.0000                     
##  NA&#39;s   :177                                                        
##       Fare           Cabin           Embarked  
##  Min.   :  0.00   Length:891         C   :168  
##  1st Qu.:  7.91   Class :character   Q   : 77  
##  Median : 14.45   Mode  :character   S   :644  
##  Mean   : 32.20                      NA&#39;s:  2  
##  3rd Qu.: 31.00                                
##  Max.   :512.33                                
## </code></pre>
<p>One important aspect when predicting using machine learning is the assessment of the completeness of the data (percentage of data with one or more values).</p>
<pre class="r"><code>missmap(train, main = &quot;Missing Values Analysis&quot;, col=c(&quot;red&quot;, &quot;gray&quot;)) # how many observations are missing</code></pre>
<p><img src="/project/titanic_files/figure-html/missing-1.png" width="672" /></p>
<pre class="r"><code>sapply(train, function(x) sum(is.na(x))) # how many observations are missing</code></pre>
<pre><code>## PassengerId    Survived      Pclass        Name         Sex         Age 
##           0           0           0           0           0         177 
##       SibSp       Parch      Ticket        Fare       Cabin    Embarked 
##           0           0           0           0         687           2</code></pre>
<p>The analysis shows that two variables suffer strongly from lack of data: Cabin and Age.</p>
<p>While a missing Cabin number simply means that the passenger has no cabin, the variable Age is crucial and its missing observations should be imputed.</p>
</div>
<div id="data-engineering" class="section level3">
<h3>Data Engineering</h3>
<div id="replace-titles-in-names" class="section level4">
<h4>Replace titles in names</h4>
<p>The preliminary data analysis puts light on the fact that the passengers titles are included to the variable Names. While the passengers names are not of a big importance here, their titles are in contrast very important and could represent an important predictor for machine learning.</p>
<p>I chose thus to isolate the titles and classify them in four different categories according to their meanings: “Miss” for young ladies, “Mrs” for older/married ones, “Mil” for military passengers and “Noble” for the aristocratic titles. The categories “Rev”, “Mr”, “Dr” and “Master” are kept unchangeable.</p>
<pre class="r"><code># 1. train$Name - Replace titles in Name

x &lt;- sub(&quot;.*, &quot;, &quot;&quot;, as.character(train$Name))
train$NameCat &lt;- sub(&quot;\\..*&quot;, &quot;&quot;, x)
train$NameCat[train$NameCat %in% c(&quot;Miss&quot;, &quot;Mlle&quot;, &quot;Ms&quot;)] &lt;- &quot;Miss&quot;
train$NameCat[train$NameCat %in% c(&quot;Mme&quot;, &quot;Mrs&quot;)] &lt;- &quot;Mrs&quot;
train$NameCat[train$NameCat %in% c(&quot;Capt&quot;, &quot;Col&quot;, &quot;Major&quot;)] &lt;- &quot;Mil&quot;
train$NameCat[train$NameCat %in% c(&quot;Don&quot;, &quot;Jonkheer&quot;, &quot;Lady&quot;, &quot;Sir&quot;, &quot;the Countess&quot;)] &lt;- &quot;Noble&quot;</code></pre>
<p>Please note however, that, contrary to what one might think, the category “Master” was used at the time to identify male children.</p>
<pre class="r"><code>ggplot(train, aes(x = NameCat, y = Age)) + geom_boxplot(aes(fill=Survived)) + theme_bw()</code></pre>
<p><img src="/project/titanic_files/figure-html/bxplt_NameCat-1.png" width="672" /></p>
</div>
<div id="create-age-categories" class="section level4">
<h4>Create Age categories</h4>
<p>For efficiency, it is more appropriate to classify the passengers according to specific age ranges using the variable Age. In this way, one could directly identify whether the passenger is a “child”, “adult” or “senior”.</p>
<p>For passengers with no information about the age, I use temporarily the category “missing”.</p>
<p>Please note also, that eventhough the Titanic’s Certificates of Clearance indicates that passengers over 14 are considered adults <a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>, I consider myself that during the evacuation of the Titanic, only signs of puberty can be used to determine whether a passenger is a child or not. For this reason, I chose the age of 14 as a limit to distinguish between an adult or a child passenger.</p>
<pre class="r"><code># 2. train$Age - Categories

train$AgeCat[train$Age &gt; 0 &amp; train$Age &lt;= 14 &amp; !is.na(train$Age)] &lt;- &quot;child&quot;
train$AgeCat[train$Age &gt; 14 &amp; train$Age &lt;= 60 &amp; !is.na(train$Age)] &lt;- &quot;adult&quot;
train$AgeCat[train$Age &gt; 60 &amp; !is.na(train$Age)] &lt;- &quot;senior&quot;
train$AgeCat[is.na(train$Age)] &lt;- &quot;missing&quot;</code></pre>
</div>
<div id="cabin-number" class="section level4">
<h4>Cabin number</h4>
<p>A new categorical variable is also set according to whether the passenger has a cabin or not.</p>
<pre class="r"><code># 3. train$Cabin

train$HasCab[!is.na(train$Cabin)] &lt;- &quot;yes&quot;
train$HasCab[is.na(train$Cabin)] &lt;- &quot;no&quot;</code></pre>
</div>
<div id="the-family-factor" class="section level4">
<h4>The “family” factor</h4>
<p>It is known that many passengers were crossing the Atlantic with other members of their families. On living the sinking Titanic, it is obvious that children should have been accompanied on lifeboats by, at least, one of their parents. Thus, being on board with other family members would play an important role.</p>
<pre class="r"><code># 4. train$HasFam
train$HasFam[train$SibSp != 0 | train$Parch != 0] &lt;- &quot;yes&quot;
train$HasFam[train$SibSp == 0 &amp; train$Parch == 0] &lt;- &quot;no&quot;</code></pre>
<p>Nevertheless, the question is: to what extent? did big families have the same chance of getting in lifeboats as smaller ones?</p>
<pre class="r"><code># Check the relationship between SibSp, Parchar and survival

ggplot(train, aes(y = SibSp, x = Parch)) +
    geom_jitter(aes(color = Survived)) +
    theme_bw() +
    geom_vline(xintercept = 3, color = &#39;black&#39;, lty=5) +
    geom_hline(yintercept = 3, color = &#39;black&#39;, lty=5)</code></pre>
<p><img src="/project/titanic_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>It appears here that passengers with SibSp or Parch greater than 3 (i.e. the passenger belonged to a family of more than 4 members) had a smaller chance to survive. I introduce thus another predictor variable which classify the passengers according to the count of their relatives on board.</p>
<pre class="r"><code># 5. train$FamCat

train$FamCat[train$SibSp + train$Parch &lt;= 4] &lt;- &quot;small&quot;     # family
train$FamCat[train$SibSp + train$Parch &gt; 4] &lt;- &quot;big&quot;        # big one
train$FamCat[train$SibSp + train$Parch == 0] &lt;- &quot;single&quot;    # the passenger was alone</code></pre>
</div>
<div id="factorize-categorical-variables" class="section level4">
<h4>Factorize categorical variables…</h4>
<p>…as all these engineered variables are to be used as categorical ones:</p>
<pre class="r"><code>train$Pclass &lt;- factor(train$Pclass)
train$NameCat &lt;- factor(train$NameCat)
train$AgeCat &lt;- factor(train$AgeCat)
train$HasCab &lt;- factor(train$HasCab)
train$HasFam &lt;- factor(train$HasFam)
train$FamCat &lt;- factor(train$FamCat)</code></pre>
</div>
</div>
<div id="detailed-exploratory-data-analysis" class="section level3">
<h3>Detailed exploratory data analysis</h3>
<p>According to the train dataset, the proportion of survival is a bit greater than the global one (one third). Not surprisingly, the women and children survived the shipwreck more than men.</p>
<p>One can also notice that the overall proportion of survival for the category “missing” seems to be very close to category “adult” which leads me to believe (even subjectively) that the mean ages of these categories would not be very different.</p>
<pre class="r"><code># barplot: survived or not
p1 &lt;- ggplot(data = train, aes(Survived, fill = Survived)) + 
    geom_bar() + guides(fill = FALSE) + 
    theme_bw()

# barplot: survival according to sex
p2 &lt;-  ggplot(data = train, aes(Sex, fill = Survived)) + 
    geom_bar(position = &quot;dodge&quot;) + guides(fill = FALSE) + 
    theme_bw()

# barplot: survival or not according to age category
p3 &lt;-  ggplot(data = train, aes(x = AgeCat, fill = Survived)) + 
    geom_bar(position = &quot;dodge&quot;) + 
    theme_bw()

grid.arrange(p1, p2, p3, layout_matrix = cbind(c(1,3), c(2,3)), widths=c(2,3))</code></pre>
<p><img src="/project/titanic_files/figure-html/DEDA-1.png" width="672" /></p>
<pre><code>## [1] &quot;The percentage of survival is about 38.4%&quot;</code></pre>
<pre><code>##   train$Sex train$Survived
## 1    female       74.20382
## 2      male       18.89081</code></pre>
<pre><code>##   train$AgeCat train$Survived
## 1        adult       39.02439
## 2        child       58.44156
## 3      missing       29.37853
## 4       senior       22.72727</code></pre>
<p>In light of the upper part of the following plot, it seems that having family members on board of the Titanic was not very crucial for survival. However, when looking to the second one, it appears clearly that being a member of a small family was relatively more important for survival, mainly because small children were always accompanied by <strong>at least</strong> one of their parents.</p>
<pre class="r"><code># barplot: survived or not according to has a family on board or not
p1 &lt;- ggplot(data = train, aes(x = HasFam, fill = Survived)) + 
    geom_bar(position = &quot;dodge&quot;) + 
    theme_bw()

# barplot: survived or not according to the category of the family
p2 &lt;- ggplot(data = train, aes(x = FamCat, fill = Survived)) + 
    geom_bar(position = &quot;dodge&quot;) + guides(fill = FALSE) + 
    theme_bw()

grid.arrange(p1, p2)</code></pre>
<p><img src="/project/titanic_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre><code>##   train$HasFam train$Survived
## 1           no       30.35382
## 2          yes       50.56497</code></pre>
<pre><code>##   train$FamCat train$Survived
## 1          big       14.89362
## 2       single       30.35382
## 3        small       56.02606</code></pre>
<p>Wealth also seems to have an import impact on survival. It appears on the two following plots that having a cabin or being a first class passenger increased clearly the chance of survival.</p>
<pre class="r"><code># barplot: survived or not according to having a cabin or not
p2 &lt;- ggplot(data = train, aes(x = HasCab, fill = Survived)) + 
    geom_bar(position = &quot;dodge&quot;) + 
    theme_bw()

# barplot: survival or not according to passenger class
p1 &lt;-  ggplot(data = train, aes(x = Pclass, fill = Survived)) + 
    geom_bar(position = &quot;dodge&quot;) + guides(fill = FALSE) + 
    theme_bw()

grid.arrange(p1, p2)</code></pre>
<p><img src="/project/titanic_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre><code>##   train$Pclass train$Survived
## 1            1       62.96296
## 2            2       47.28261
## 3            3       24.23625</code></pre>
<pre><code>##   train$HasCab train$Survived
## 1           no       29.98544
## 2          yes       66.66667</code></pre>
<p>On the other side, it appears also clearly that the <strong>overwhelming majority</strong> of women who bought their tickets more than 50 pounds survived. Since it is not the case for men, the reason could be that the women from first class were the first to leave the Titanic on lifeboats when men of the first class was forced to wait for women and children from other classes.</p>
<pre class="r"><code># Had the Fare any impact? 
ggplot(train, aes(x = PassengerId, y = Fare, color = Survived)) + 
    geom_point() + 
    theme_bw() + 
    facet_grid(. ~ Sex)</code></pre>
<p><img src="/project/titanic_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>The variable Fare seems also to correlate globally to age categories and can thus be of a good benefit when imputing the missing ageCat values. Nevertheless, to overcome the skewed distribution of the variable Fare, an appropriate less sensitive classifier method should be used (Random Forest or Gradient Boosting Method can do the job in such cases)</p>
<pre class="r"><code># How evolves the Fare according to passengers age (depending on age categories)
ggplot(train,aes(x = Age,y = Fare, color = AgeCat)) + geom_point(shape = 1) + 
     geom_smooth(method=&#39;lm&#39;) + scale_y_continuous(limits = c(0, 300)) + 
    theme_bw()</code></pre>
<p><img src="/project/titanic_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<pre class="r"><code># How evolves the Fare according to passengers age (overall)
ggplot(train,aes(x = Age,y = Fare)) + geom_point(color = &quot;red&quot;) + 
    geom_smooth(method=&#39;lm&#39;) + scale_y_continuous(limits = c(0, 300)) + 
    theme_bw()</code></pre>
<p><img src="/project/titanic_files/figure-html/unnamed-chunk-14-2.png" width="672" /></p>
<p>Concerning the passengers titles, the proportions of survival for each category correlate to age categories and sex as pointed out above. One can notice also that certain categories such as Doctors, servicemen or clerics did not survive for the majority (did not even tried to leave the Titanic?).</p>
<pre class="r"><code># Relationship between survival and name categories
ggplot(data = train, aes(x = NameCat, fill = Survived)) + 
    geom_bar(position = &quot;dodge&quot;) + 
    theme_bw()</code></pre>
<p><img src="/project/titanic_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre class="r"><code>aggregate(train$Survived ~ train$NameCat, FUN= function(x) sum(x == &quot;yes&quot;) / length(x) * 100)</code></pre>
<pre><code>##   train$NameCat train$Survived
## 1            Dr       42.85714
## 2        Master       57.50000
## 3           Mil       40.00000
## 4          Miss       70.27027
## 5            Mr       15.66731
## 6           Mrs       79.36508
## 7         Noble       60.00000
## 8           Rev        0.00000</code></pre>
</div>
<div id="curiosity-not-directly-related-to-the-topic-of-the-project" class="section level3">
<h3>CURIOSITY (not directly related to the topic of the project)</h3>
<pre class="r"><code># Relatioship between passengers title and passengers class
# Difference in social classes (exception for &quot;Master&quot;)
p &lt;- ggplot(data = train, aes(Pclass, fill = Pclass)) + 
    geom_bar() + 
    theme_bw()

p + facet_grid(. ~ NameCat)</code></pre>
<p><img src="/project/titanic_files/figure-html/curiosity-1.png" width="672" /></p>
<pre class="r"><code># Relationship between age categories and passengers class 
# (interesting concerning the category &quot;missing&quot; which seems, according to its
# distribution, to be close to &quot;adult&quot;) (suppose that most of the passengers with 
# &quot;missing&quot; ages are in fact &quot;adults&quot;)
p + facet_grid(. ~ AgeCat)</code></pre>
<p><img src="/project/titanic_files/figure-html/curiosity-2.png" width="672" /></p>
</div>
<div id="data-imputation" class="section level3">
<h3>Data Imputation</h3>
<p>In order to predict the target variable, it is important to impute all missing values of the predictors. There are many methods for the imputation, each with advantages and inconvenients. For this project, two variables show missing values: Embarked and Age (Fare and Age for test data). Since only two values are missing in Embarked, I do a little investigation to deduct them from the ticket number, provided that it should be related to the place were it was issued.</p>
<pre class="r"><code># 1. train$Embarked

# passengerID with missing &quot;Embarked&quot;
train$PassengerId[is.na(train$Embarked)] </code></pre>
<pre><code>## [1]  62 830</code></pre>
<pre class="r"><code># both passengerd have same ticket: 113572 =&gt; they embarked together with the same
# ticket
train$Ticket[is.na(train$Embarked)]</code></pre>
<pre><code>## [1] &quot;113572&quot; &quot;113572&quot;</code></pre>
<pre class="r"><code># check other passengers with ticket of the same prefix =&gt; they most probably bought 
# their tickets from the same embarkment place
train$Embarked[grep(&quot;^1135&quot;, train$Ticket)] </code></pre>
<pre><code>## [1] C    &lt;NA&gt; S    S    S    S    C    S    &lt;NA&gt;
## Levels: C Q S</code></pre>
<pre class="r"><code># since most of the last cases have value &quot;S&quot; for Embarkment I give the same for the
# missing ones:
train$Embarked[is.na(train$Embarked)] &lt;- &quot;S&quot;</code></pre>
<p>Concerning the missing values of Age, I decided to use the variable AgeCat instead to avoid imputing numerical values. The missing values are imputed using Random Forest algorithm since it appears, as pointed out above, that the age category of the passengers is related directly to many parameters included in our dataset. Of course, the variable Survived is excluded when training the model.</p>
<p>Although it is possible to merge training and data set for the computation of a unique model, I prefer to do the computation for each set separately. The chosed classifiers are: “Pclass”, “Sex”, “Embarked”, “Fare,”NameCat“,”HasCab“, and”FamCat&quot; while the target variable is “AgeCat” with three different levels: “child”, “adult”, and “senior”.</p>
<p>The trainControl was set to use the K-fold cross-validation as it represents a robust method to estimate the model’s accuracy. The choice of k = 5 has been empirically shown to avoid high bias and variance when estimating the test error rate <a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>.</p>
<pre class="r"><code># train$Age
# The imputation is predicted
# 1. Select the predictors - &quot;Survived&quot;&quot; should not be selected
trainAgetrain &lt;- train[c(1, 3, 5, 10, 12, 13, 14, 15, 17)]

# keep only observations with AgeCat = &quot;missing&quot; in the test subset
trainAgetest &lt;- trainAgetrain[trainAgetrain$AgeCat == &quot;missing&quot;,]

# exclude AgeCat from the test subset
trainAgetest &lt;- trainAgetest[, -7]

# exclude observations with AgeCat = &quot;missing&quot; in the train subset
trainAgetrain &lt;- trainAgetrain[trainAgetrain$AgeCat != &quot;missing&quot;,] 
trainAgetrain &lt;- trainAgetrain[, -1]

# exclude the level &quot;missing&quot;
trainAgetrain$AgeCat &lt;- factor(trainAgetrain$AgeCat)

# Subset the train data set
set.seed(1962)
subsets &lt;- createDataPartition(y=trainAgetrain$AgeCat, p=0.75, list=FALSE)
subTraining &lt;- trainAgetrain[subsets, ] 
subTesting &lt;- trainAgetrain[-subsets, ]

# train the model
x &lt;- subTraining[, -6] # column 6 is the target variable
y &lt;- subTraining[, 6]
control = trainControl(method = &quot;cv&quot;, number = 5, allowParallel = TRUE)
modelRFtrain &lt;- train(x, y, method = &quot;rf&quot;, trControl = control)  # I use random forest </code></pre>
<pre class="r"><code>#modelRFtrain$results
predRFtrain &lt;- predict(modelRFtrain, subTesting)
cfMatRFtrain &lt;- confusionMatrix(subTesting$AgeCat, predRFtrain)
cfMatRFtrain$overall</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##     0.93785311     0.70165492     0.89152431     0.96857126     0.90395480 
## AccuracyPValue  McnemarPValue 
##     0.07426355            NaN</code></pre>
<pre class="r"><code>cfMatRFtrain$table</code></pre>
<pre><code>##           Reference
## Prediction adult child senior
##     adult    151     2      0
##     child      4    15      0
##     senior     5     0      0</code></pre>
<pre class="r"><code>importanceRFtrain &lt;- varImp(modelRFtrain,scale = FALSE)
plot(importanceRFtrain, top= 10)</code></pre>
<p><img src="/project/titanic_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>The obtained model shows a very good accuracy on training subset. The most important predictors are resp. NameCat, Fare and FamCat. This result is not surprising as this relationship appeared clearly in the exploratory data analysis.</p>
<p>The missing values of AgeCat in train data are then predicted using the obtained RF model.</p>
<pre class="r"><code># predict for the missing AgeCat in train data set
predAgetrain &lt;- predict(modelRFtrain, trainAgetest)

# values are then injected into train
train$AgeCat[train$PassengerId %in% trainAgetest$PassengerId] &lt;- predAgetrain
train$AgeCat &lt;- factor(train$AgeCat)
# ifelse(train$AgeCat[trainAgetest$PassengerId] == predAge, 1, 0)</code></pre>
</div>
<div id="adapting-the-test-file" class="section level3">
<h3>Adapting the test file</h3>
<p>In order to predict survival, the test data should be modified in the same way as for the train data.</p>
<pre class="r"><code>sapply(test, function(x) sum(is.na(x))) # how many observations are missing</code></pre>
<pre><code>## PassengerId      Pclass        Name         Sex         Age       SibSp 
##           0           0           0           0          86           0 
##       Parch      Ticket        Fare       Cabin    Embarked 
##           0           0           1         327           0</code></pre>
<p>We notice here missing values in Age and Fare. Concerning Fare, and since it is only one value missing, one could simply assign to this observation the median Fare value of its corresponding class.</p>
<p>The missing values of AgeCat are imputed using the exact same method as for the train data.</p>
<p>Many titles seen in the train file are missing in test file. At the same time, a new one, <strong>Dona</strong>, is classified as a noble title.</p>
<pre class="r"><code># Data Engineering

# 1. test$Name
x &lt;- sub(&quot;.*, &quot;, &quot;&quot;, as.character(test$Name))
test$NameCat &lt;- sub(&quot;\\..*&quot;, &quot;&quot;, x)
test$NameCat[test$NameCat %in% c(&quot;Miss&quot;, &quot;Ms&quot;)] &lt;- &quot;Miss&quot;
test$NameCat[test$NameCat == &quot;Col&quot;] &lt;- &quot;Mil&quot;
test$NameCat[test$NameCat == &quot;Dona&quot;] &lt;- &quot;Noble&quot;

# 2. test$Age
test$AgeCat[test$Age &gt; 0 &amp; test$Age &lt;= 14 &amp; !is.na(test$Age)] &lt;- &quot;child&quot;
test$AgeCat[test$Age &gt; 14 &amp; test$Age &lt;= 60 &amp; !is.na(test$Age)] &lt;- &quot;adult&quot;
test$AgeCat[test$Age &gt; 60 &amp; !is.na(test$Age)] &lt;- &quot;senior&quot;
test$AgeCat[is.na(test$Age)] &lt;- &quot;missing&quot;

# 3. test$Cabin
test$HasCab[!is.na(test$Cabin)] &lt;- &quot;yes&quot;
test$HasCab[is.na(test$Cabin)] &lt;- &quot;no&quot;

# 4. Add test$HasFam
test$HasFam[test$SibSp != 0 | test$Parch != 0] &lt;- &quot;yes&quot;
test$HasFam[test$SibSp == 0 &amp; test$Parch == 0] &lt;- &quot;no&quot;

# 5. Add test$Famcat
test$FamCat[test$SibSp + test$Parch &lt;= 4] &lt;- &quot;small&quot;
test$FamCat[test$SibSp + test$Parch &gt; 4] &lt;- &quot;big&quot;
test$FamCat[test$SibSp + test$Parch == 0] &lt;- &quot;single&quot;

# 6. missing Fare: PassengerId = 1044 with Pclass = 3 -&gt; use the median for pclass
test$Fare[test$PassengerId == 1044] &lt;- median(test$Fare[test$Pclass == 3], na.rm = TRUE)

test$NameCat &lt;- factor(test$NameCat)
test$AgeCat &lt;- factor(test$AgeCat)
test$HasCab &lt;- factor(test$HasCab)
test$HasFam &lt;- factor(test$HasFam)
test$FamCat &lt;- factor(test$FamCat)

#Imputation of missing test$Age
testAgetrain &lt;- test[c(1, 2, 4, 9, 11, 12, 13, 14, 16)]
testAgetest &lt;- testAgetrain[testAgetrain$AgeCat == &quot;missing&quot;,]
testAgetest &lt;- testAgetest[, -7]                                    # test file
testAgetrain &lt;- testAgetrain[testAgetrain$AgeCat != &quot;missing&quot;,]
testAgetrain &lt;- testAgetrain[, -1]                                  # train file
testAgetrain$AgeCat &lt;- factor(testAgetrain$AgeCat)                  # in case of different levels
set.seed(1962)
subsets &lt;- createDataPartition(y=testAgetrain$AgeCat, p=0.75, list=FALSE)
subTraining &lt;- testAgetrain[subsets, ] 
subTesting &lt;- testAgetrain[-subsets, ]
x &lt;- subTraining[, -6]                                              # column 6 is the target variable
y &lt;- subTraining[, 6]
control = trainControl(method = &quot;cv&quot;, number = 5, allowParallel = TRUE)
modelRFtest &lt;- train(x, y, method = &quot;rf&quot;, trControl = control)</code></pre>
<pre class="r"><code>#modelRFtest$results
predRFtest &lt;- predict(modelRFtest, subTesting)
cfMatRFtest &lt;- confusionMatrix(subTesting$AgeCat, predRFtest)
cfMatRFtest$overall</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##      0.8765432      0.4409938      0.7846553      0.9391798      0.8641975 
## AccuracyPValue  McnemarPValue 
##      0.4510839            NaN</code></pre>
<pre class="r"><code>cfMatRFtest$table</code></pre>
<pre><code>##           Reference
## Prediction adult child senior
##     adult     66     5      1
##     child      2     5      0
##     senior     2     0      0</code></pre>
<pre class="r"><code>predtestAgetest &lt;- predict(modelRFtest, testAgetest)
test$AgeCat[test$PassengerId %in% testAgetest$PassengerId] &lt;- predtestAgetest
test$AgeCat &lt;- factor(test$AgeCat)</code></pre>
</div>
<div id="prediction-of-survival" class="section level3">
<h3>Prediction of survival</h3>
<p>Now that all the data is processed and missing values imputed, lets compute the final model and predict survival among the passengers in the test list.</p>
<p>Contrarily to the imputation of AgeCat, the boosting methods proved to be more effective as they better accomodate:</p>
<ol style="list-style-type: decimal">
<li><p>the small variance of the selected predictors provided that the outcome reduces to only two values: Survived or not,</p></li>
<li><p>the high bias that could be induced by the use of categorical predictors.</p></li>
</ol>
<p>For these reasons, I decided to use the gradient boosting method (GBM) to predict the survival.</p>
<p>The <strong>predictor variables</strong> are: “Pclass”, “Sex”, “Fare”“,”Embarked“,”NameCat“,”AgeCat“,”HasCab“, and”FamCat“.</p>
<p>The <strong>target variable</strong> is “Survived”.</p>
<p>The train data consists in 891 observations while the test data consists in 418.</p>
<pre class="r"><code># RF for train and test
trainFin &lt;- train[c(2, 3, 5, 10, 12, 13, 14, 15, 17)]
#trainFin$Survived &lt;- factor(trainFin$Survived)
testFin &lt;- test[c(1, 2, 4, 9, 11, 12, 13, 14, 16)]
set.seed(1962)
subsets &lt;- createDataPartition(y=trainFin$AgeCat, p=0.75, list=FALSE)
subTraining &lt;- trainFin[subsets, ]
subTesting &lt;- trainFin[-subsets, ]
x &lt;- subTraining[, -1] # column 1 is the target variable
y &lt;- subTraining[, 1]
control = trainControl(method = &quot;boot&quot;, number = 5, allowParallel = TRUE)
modelGBMFin &lt;- train(x, y, method = &quot;gbm&quot;, trControl = control)</code></pre>
<pre class="r"><code>#modelGBMFin$results
predGBMFin &lt;- predict(modelGBMFin, subTesting)
cfMatGBMFin &lt;- confusionMatrix(subTesting$Survived, predGBMFin)
cfMatGBMFin$overall</code></pre>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##   8.108108e-01   5.901899e-01   7.530008e-01   8.601154e-01   6.576577e-01 
## AccuracyPValue  McnemarPValue 
##   3.427043e-07   2.800872e-01</code></pre>
<pre class="r"><code>cfMatGBMFin$table</code></pre>
<pre><code>##           Reference
## Prediction  no yes
##        no  121  17
##        yes  25  59</code></pre>
<pre class="r"><code>predGBMFin &lt;- predict(modelGBMFin, testFin)
sol &lt;- ifelse(predGBMFin == &quot;yes&quot;, &quot;1&quot;, &quot;0&quot;)
z &lt;- data.frame(test$PassengerId, sol)
colnames(z) &lt;- c(&quot;PassengerId&quot;, &quot;Survived&quot;)
write.csv(z, &quot;Res.csv&quot;, row.names=FALSE)</code></pre>
<p>The model obtained had an accuracy of 0.77511. Nevertheless, another model obtained just by replacing FamCat with HasFam reaches an accuracy of 0.80382 and ended much higher on the leaderboard.</p>
</div>
<div id="bibliography" class="section level3">
<h3>Bibliography</h3>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Mersey, Lord (1999) [1912]. The Loss of the Titanic, 1912. The Stationery Office. ISBN 978-0-11-702403-8<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p><a href="https://www.encyclopedia-titanica.org/titanic-statistics.html" class="uri">https://www.encyclopedia-titanica.org/titanic-statistics.html</a><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="http://www.sthda.com/english/articles/38-regression-model-validation/157-cross-validation-essentials-in-r/" class="uri">http://www.sthda.com/english/articles/38-regression-model-validation/157-cross-validation-essentials-in-r/</a><a href="#fnref3">↩</a></p></li>
</ol>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="label label-default" href="https://slamara.github.io/tags/exploratory-data-analysis/">Exploratory Data Analysis</a>
  
  <a class="label label-default" href="https://slamara.github.io/tags/data-visualisation/">Data Visualisation</a>
  
  <a class="label label-default" href="https://slamara.github.io/tags/machine-learning/">Machine Learning</a>
  
</div>




    
    
    

    
      
      
      
      

      
      
      
      
    

  </div>
</article>



<footer class="site-footer">
  <div class="container">

    
    <p class="powered-by">
      <a href="https://slamara.github.io/privacy/">Privacy Policy</a>
    </p>
    

    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//slamara.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>

