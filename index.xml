<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Samir Lamara on Samir Lamara</title>
    <link>https://slamara.github.io/</link>
    <description>Recent content in Samir Lamara on Samir Lamara</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Influence of automatic and manual transmission on fuel consumption</title>
      <link>https://slamara.github.io/project/fuelconsumption/</link>
      <pubDate>Wed, 08 Aug 2018 16:53:36 +0200</pubDate>
      
      <guid>https://slamara.github.io/project/fuelconsumption/</guid>
      <description>&lt;div id=&#34;executive-summary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Executive summary:&lt;/h2&gt;
&lt;p&gt;The purpose of this project is to assess qualitatively and quantitatively the leverage of automatic and manual transmission (&lt;strong&gt;am&lt;/strong&gt;) on the fuel consumption (&lt;strong&gt;mpg&lt;/strong&gt;) of a selection of 32 cars. This should be done with regards to the intrinsic relationship of &lt;strong&gt;mpg&lt;/strong&gt; and &lt;strong&gt;am&lt;/strong&gt; with 10 other car aspects and performances. The data used in this assignment was published in the 1974 Motors Trend magazine.&lt;/p&gt;
&lt;p&gt;In this short report, I start with an exploratory analysis and rapid graphical representation focusing roughly on the &lt;strong&gt;am&lt;/strong&gt; and &lt;strong&gt;mpg&lt;/strong&gt;. In the second part I examine different models and select the best one inferring the relationship between these variables. The report ends with a conclusion.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dataset “mtcars” can be loaded with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    32 obs. of  11 variables:
##  $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
##  $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
##  $ disp: num  160 160 108 258 360 ...
##  $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
##  $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
##  $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
##  $ qsec: num  16.5 17 18.6 19.4 17 ...
##  $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...
##  $ am  : num  1 1 1 0 0 0 0 0 0 0 ...
##  $ gear: num  4 4 4 3 3 3 3 4 4 4 ...
##  $ carb: num  4 4 1 1 2 1 4 2 2 4 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data set consists of 11 different characteristics of 32 car models from the 70’s.&lt;/p&gt;
&lt;p&gt;The box plot computed for &lt;strong&gt;mpg&lt;/strong&gt; with regards to &lt;strong&gt;am&lt;/strong&gt; shows clearly that the manual transmission have a higher &lt;strong&gt;mpg&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qplot(as.factor(am), mpg, data = mtcars, geom = &amp;quot;boxplot&amp;quot;, color = as.factor(am), 
      xlab = &amp;quot;Type of transmission(0: automatic, 1: manual)&amp;quot;, 
      ylab = &amp;quot;Number of miles per gallon&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/fuelConsumption_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;However, the correlation between &lt;strong&gt;mpg&lt;/strong&gt; and the other parameters shows a stronger relationship between &lt;strong&gt;mpg&lt;/strong&gt; and &lt;strong&gt;wt&lt;/strong&gt;, &lt;strong&gt;cyl&lt;/strong&gt;, &lt;strong&gt;disp&lt;/strong&gt;, &lt;strong&gt;hp&lt;/strong&gt;, &lt;strong&gt;drat&lt;/strong&gt;, &lt;strong&gt;vs&lt;/strong&gt; as compared to &lt;strong&gt;am&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr &amp;lt;- cor(mtcars$mpg, mtcars)
corr[1, order(-abs(corr[1,]))]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        mpg         wt        cyl       disp         hp       drat 
##  1.0000000 -0.8676594 -0.8521620 -0.8475514 -0.7761684  0.6811719 
##         vs         am       carb       gear       qsec 
##  0.6640389  0.5998324 -0.5509251  0.4802848  0.4186840&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hence, I consider that since &lt;strong&gt;mpg&lt;/strong&gt; is strongly correlated with other parameters, it could be misleading to ignore their effects on its relationship with the automatic and manual transmissions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-selection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model selection&lt;/h2&gt;
&lt;p&gt;As first look, I compute a regression model with &lt;strong&gt;mpg&lt;/strong&gt; as the outcome and &lt;strong&gt;am&lt;/strong&gt; as the regressor:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1 &amp;lt;- lm(mpg ~ am, mtcars)
summary(fit1)$coef&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Estimate Std. Error   t value     Pr(&amp;gt;|t|)
## (Intercept) 17.147368   1.124603 15.247492 1.133983e-15
## am           7.244939   1.764422  4.106127 2.850207e-04&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The estimate of the intercept represents the hypothetical fuel efficiency in case of automatic transmission (am = 0) while the estimate of &lt;strong&gt;am&lt;/strong&gt; represents the slope for the case of manual transmission (am = 1).&lt;/p&gt;
&lt;p&gt;Fitting all parameters of mtcars:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit2 &amp;lt;- lm(mpg ~ ., mtcars)
summary(fit2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = mpg ~ ., data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4506 -1.6044 -0.1196  1.2193  4.6271 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)  
## (Intercept) 12.30337   18.71788   0.657   0.5181  
## cyl         -0.11144    1.04502  -0.107   0.9161  
## disp         0.01334    0.01786   0.747   0.4635  
## hp          -0.02148    0.02177  -0.987   0.3350  
## drat         0.78711    1.63537   0.481   0.6353  
## wt          -3.71530    1.89441  -1.961   0.0633 .
## qsec         0.82104    0.73084   1.123   0.2739  
## vs           0.31776    2.10451   0.151   0.8814  
## am           2.52023    2.05665   1.225   0.2340  
## gear         0.65541    1.49326   0.439   0.6652  
## carb        -0.19942    0.82875  -0.241   0.8122  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 2.65 on 21 degrees of freedom
## Multiple R-squared:  0.869,  Adjusted R-squared:  0.8066 
## F-statistic: 13.93 on 10 and 21 DF,  p-value: 3.793e-07&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The higher value of R-squared suggests a better fit for this model. However, the p-values, which represent the significance of each parameter in presence of the others, are very high. Thus, to determine statistically the best fitting model I use the &lt;strong&gt;step&lt;/strong&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best &amp;lt;- step(fit2, direction = &amp;quot;both&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(best)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = mpg ~ wt + qsec + am, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4811 -1.5555 -0.7257  1.4110  4.6610 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)   9.6178     6.9596   1.382 0.177915    
## wt           -3.9165     0.7112  -5.507 6.95e-06 ***
## qsec          1.2259     0.2887   4.247 0.000216 ***
## am            2.9358     1.4109   2.081 0.046716 *  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 2.459 on 28 degrees of freedom
## Multiple R-squared:  0.8497, Adjusted R-squared:  0.8336 
## F-statistic: 52.75 on 3 and 28 DF,  p-value: 1.21e-11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to the step function, the best model accounts for &lt;strong&gt;am&lt;/strong&gt;, &lt;strong&gt;wt&lt;/strong&gt; and &lt;strong&gt;qsec&lt;/strong&gt;. The R-squared is in this case significant and the p-values small. The coefficient of &lt;strong&gt;am&lt;/strong&gt; shows an &lt;strong&gt;mpg&lt;/strong&gt; higher of about 2.94 miles per gallon in the case of manual transmission.&lt;/p&gt;
&lt;p&gt;The plots of the residuals Vs. fitted values, the square root of the standard residuals Vs. fitted values, the standard residuals Vs. Leverage and the QQ-plot are given by:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow = c(2, 2))
plot(best)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/fuelConsumption_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While the QQ-plot seems to be relatively acceptable, the other plots show that the assumptions of normality and linearity are close to be breached.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The final results don’t permit to be confident in concluding a better efficiency of the manual transmission. All I can say in this case is that the quantification of the difference in fuel efficiency between the automatic and manual transmission is only about 3 miles per gallon with a p confidence of 0.046. Due to the small number of observations, only the inclusion of more data can probably improve the confidence in the qualitative and quantitative findings.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Personal activity monitoring</title>
      <link>https://slamara.github.io/project/activitymonitoring/</link>
      <pubDate>Wed, 08 Aug 2018 16:40:59 +0200</pubDate>
      
      <guid>https://slamara.github.io/project/activitymonitoring/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This project makes use of data from a personal activity monitoring device which counts the number of steps taken by an anonymous individual in 5 minutes intervals throughout the day. The &lt;a href=&#34;https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip&#34;&gt;dataset&lt;/a&gt; was collected within a period of two months (October and November 2012).&lt;/p&gt;
&lt;p&gt;The variables included in this dataset are:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;steps&lt;/strong&gt;: Number of steps taking in a 5-minute interval (missing values are coded as NA)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;date&lt;/strong&gt;: The date on which the measurement was taken in YYYY-MM-DD format&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;interval&lt;/strong&gt;: Identifier for the 5-minute interval in which measurement was taken&lt;/p&gt;
&lt;p&gt;The dataset is stored in a comma-separated-value (CSV) file with a total of 17,568 observations.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;loading-and-preprocessing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Loading and preprocessing the data:&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(xtable)
library(chron)
library(lattice)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;activity &amp;lt;- read.csv(&amp;quot;./activityMonitoring/activity.csv&amp;quot;)

activity$date &amp;lt;- as.Date(activity$date, format=&amp;quot;%Y-%m-%d&amp;quot;)

str(activity)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    17568 obs. of  3 variables:
##  $ steps   : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ date    : Date, format: &amp;quot;2012-10-01&amp;quot; &amp;quot;2012-10-01&amp;quot; ...
##  $ interval: int  0 5 10 15 20 25 30 35 40 45 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-the-mean-total-number-of-steps-taken-per-day&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is the mean total number of steps taken per day?&lt;/h2&gt;
&lt;p&gt;I first calculate the total number of steps taken per day:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;StepsPerDay &amp;lt;- activity %&amp;gt;% na.omit() %&amp;gt;% group_by(date) %&amp;gt;% summarise(TotSteps = sum(steps))

StepsPerDay&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 53 x 2
##    date       TotSteps
##    &amp;lt;date&amp;gt;        &amp;lt;int&amp;gt;
##  1 2012-10-02      126
##  2 2012-10-03    11352
##  3 2012-10-04    12116
##  4 2012-10-05    13294
##  5 2012-10-06    15420
##  6 2012-10-07    11015
##  7 2012-10-09    12811
##  8 2012-10-10     9900
##  9 2012-10-11    10304
## 10 2012-10-12    17382
## # ... with 43 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then, I make a histogram of the total number of steps taken each day:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(StepsPerDay$date, StepsPerDay$TotSteps, type=&amp;quot;h&amp;quot;, lwd=5, col=&amp;quot;red&amp;quot;, 
     xlab=&amp;quot;Days&amp;quot;, 
     ylab=&amp;quot;Number of steps&amp;quot;, 
     main=&amp;quot;Total number of steps taken each day&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/activityMonitoring_files/figure-html/histo1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally, I calculate and report the mean and median of the total number of steps taken per day&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(StepsPerDay$TotSteps)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10766.19&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;median(StepsPerDay$TotSteps)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10765&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-the-average-daily-activity-pattern&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is the average daily activity pattern?&lt;/h2&gt;
&lt;p&gt;To show the pattern, I make a time series plot (i.e. type = “l”) of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MeanInterval &amp;lt;- aggregate(activity$steps, 
                          by=list(interval=activity$interval), 
                          FUN = mean, na.rm = TRUE)

plot(MeanInterval$interval, MeanInterval$x, type = &amp;quot;l&amp;quot;, col = &amp;quot;blue&amp;quot;, 
     xlab = &amp;quot;5-minute intervals&amp;quot;, 
     ylab = &amp;quot;Average nummber of steps&amp;quot;, 
     main = &amp;quot;Average number of steps averaged across all days&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/activityMonitoring_files/figure-html/timeSerie1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MeanInterval[which.max(MeanInterval$x),]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     interval        x
## 104      835 206.1698&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;imputing-missing-values&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Imputing missing values&lt;/h2&gt;
&lt;p&gt;I first calculate and report the total number of missing values in the dataset (i.e. the total number of rows with NAs)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(is.na(activity$steps))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2304&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a strategy for filling in all of the missing values in the dataset, I use &lt;strong&gt;dplyr&lt;/strong&gt; to group the data according to the day and replace the NA with the average number of steps across all days of its corresponding interval (from the table &lt;strong&gt;MeanInterval&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;I create then a new dataset that is equal to the original dataset but with the missing data filled in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;activityFull &amp;lt;- activity %&amp;gt;% group_by(date) %&amp;gt;% mutate(steps = ifelse(is.na(steps), MeanInterval$x[match(interval, MeanInterval$interval)], steps))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A histogram of the total number of steps taken each day is then re-calculated as well as the mean and median total number of steps taken per day.&lt;/p&gt;
&lt;p&gt;While the new mean is exactly the same as in the first part, the median differs too slightly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;StepsPerDayFull &amp;lt;- activityFull %&amp;gt;% group_by(date) %&amp;gt;% summarise(TotSteps = sum(steps))

plot(StepsPerDayFull$date, StepsPerDayFull$TotSteps, type=&amp;quot;h&amp;quot;, lwd=5, col=&amp;quot;red&amp;quot;, 
     xlab=&amp;quot;Days&amp;quot;, 
     ylab=&amp;quot;Number of steps&amp;quot;, 
     main=&amp;quot;Total number of steps taken each day obtained from a full data set&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/activityMonitoring_files/figure-html/histo2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Recap &amp;lt;- xtable(cbind(c(&amp;quot;Without \&amp;quot;NA\&amp;quot;&amp;quot;, &amp;quot;With \&amp;quot;NA\&amp;quot;&amp;quot;), c(mean(StepsPerDayFull$TotSteps), mean(StepsPerDay$TotSteps)), c(median(StepsPerDayFull$TotSteps), median(StepsPerDay$TotSteps))))

colnames(Recap) &amp;lt;- c(&amp;quot;Type of data set&amp;quot;, &amp;quot;Mean&amp;quot;, &amp;quot;Median&amp;quot;)

rownames(Recap) &amp;lt;- NULL

print(Recap, include.rownames=FALSE, type=&amp;quot;html&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;!-- html table generated in R 3.5.1 by xtable 1.8-2 package --&gt;
&lt;!-- Wed Aug 08 17:03:30 2018 --&gt;
&lt;table border=&#34;1&#34;&gt;
&lt;tr&gt;
&lt;th&gt;
Type of data set
&lt;/th&gt;
&lt;th&gt;
Mean
&lt;/th&gt;
&lt;th&gt;
Median
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
Without “NA”
&lt;/td&gt;
&lt;td&gt;
10766.1886792453
&lt;/td&gt;
&lt;td&gt;
10766.1886792453
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
With “NA”
&lt;/td&gt;
&lt;td&gt;
10766.1886792453
&lt;/td&gt;
&lt;td&gt;
10765
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;are-there-differences-in-activity-patterns-between-weekdays-and-weekends&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Are there differences in activity patterns between weekdays and weekends?&lt;/h2&gt;
&lt;p&gt;I first create a new factor variable in the dataset with two levels “weekday” and “weekend” indicating whether a given date is a weekday or a weekend day.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;activityFull &amp;lt;- activityFull %&amp;gt;% mutate(WE = weekdays(date)) %&amp;gt;% mutate(WE = ifelse(WE == &amp;quot;Samstag&amp;quot;|WE == &amp;quot;Sonntag&amp;quot;, &amp;quot;weekend&amp;quot;, &amp;quot;weekday&amp;quot;))

# With the library &amp;quot;Chron&amp;quot;:
# activityFulltest &amp;lt;- activityFull %&amp;gt;% mutate(WE = ifelse(is.weekend(date), &amp;quot;weekend&amp;quot;, &amp;quot;weekday&amp;quot;)

table(activityFull$WE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## weekday weekend 
##   12960    4608&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I make a panel plot containing a time series plot (i.e. type = “l”) of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MeanIntervalFull &amp;lt;- aggregate(activityFull$steps, 
                              by=list(interval=activityFull$interval, WE=activityFull$WE), 
                              FUN = mean)

xyplot(x ~ interval | as.factor(WE), data = MeanIntervalFull, type = &amp;quot;l&amp;quot;, 
       xlab = &amp;quot;Interval&amp;quot;, 
       ylab = &amp;quot;Number of steps&amp;quot;, 
       main = &amp;quot;The average number of steps across all weekday days or weekend days&amp;quot;, 
       layout = c(1,2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/activityMonitoring_files/figure-html/PanelPlot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Evolution of fine particulate matter pollution in the US</title>
      <link>https://slamara.github.io/project/airquality/</link>
      <pubDate>Wed, 08 Aug 2018 16:24:41 +0200</pubDate>
      
      <guid>https://slamara.github.io/project/airquality/</guid>
      <description>&lt;p&gt;Among the numerous air pollutants, the fine particulate matter (PM2.5) is one of the most harmful to human health. In the US, the Environmental Protection Agency (EPA) is in charge of setting the ambient air quality standards, tracking the emissions of the pollutants into the atmosphere, and releasing a database on emissions approximatly every 3 years. This database is known as the National Emissions Inventory (NEI). For more details, see the &lt;a href=&#34;http://www.epa.gov/ttn/chief/eiinformation.html&#34;&gt;EPA National Emissions Inventory web site&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this Database, the NEI records, for each year, how many tons of PM2.5 were emitted. The data used in this project are for 1999, 2002, 2005, and 2008 and can be downloaded &lt;a href=&#34;https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My goal within this report is to explore the National Emissions Inventory database and see what it says about fine particulate matter pollution in the United states over the 10-year period 1999–2008.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Data frame with all of the PM2.5 emissions data for 1999, 2002, 2005, and 2008
NEI &amp;lt;- readRDS(&amp;quot;./airQuality/summarySCC_PM25.rds&amp;quot;)

# mapping from the SCC digit strings in the Emissions table to the actual name of
# the PM2.5 source
SCC &amp;lt;- readRDS(&amp;quot;./airQuality/Source_Classification_Code.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;have-total-emissions-from-pm2.5-decreased-in-the-united-states-from-1999-to-2008&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Have total emissions from PM2.5 decreased in the United States from 1999 to 2008?&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;totalEm &amp;lt;- with(NEI, tapply(Emissions, year, sum, na.rm = TRUE))

plot(names(totalEm), totalEm, type =&amp;quot;l&amp;quot;, 
     xlab = &amp;quot;Year&amp;quot;, 
     ylab = &amp;quot;Total Pm(2.5) Emissions (tons)&amp;quot;, 
     main = &amp;quot;Evolution of the total PM2.5 Emissions over the US&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/airQuality_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;have-total-emissions-from-pm2.5-decreased-in-the-baltimore-city-maryland-fips24510-from-1999-to-2008&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Have total emissions from PM2.5 decreased in the Baltimore City, Maryland (fips==“24510”) from 1999 to 2008?&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NEIBal &amp;lt;- subset(NEI, fips == &amp;quot;24510&amp;quot;)

totalEmBal &amp;lt;- with(NEIBal, tapply(Emissions, year, sum, na.rm = TRUE))

plot(names(totalEmBal), totalEmBal, type =&amp;quot;l&amp;quot;, 
     xlab = &amp;quot;Year&amp;quot;,
     ylab = &amp;quot;Total Pm2.5 Emissions (tons)&amp;quot;,
     main = &amp;quot;Evolution of the total PM2.5 Emissions in Baltimore&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/airQuality_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;of-the-four-types-of-sources-indicated-by-the-type-point-nonpoint-onroad-nonroad-variable-which-of-these-four-sources-have-seen-decreases-in-emissions-from-19992008-for-baltimore-city-which-have-seen-increases-in-emissions-from-19992008&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Of the four types of sources indicated by the type (point, nonpoint, onroad, nonroad) variable, which of these four sources have seen decreases in emissions from 1999–2008 for Baltimore City? Which have seen increases in emissions from 1999–2008?&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;totalEmBalTypes &amp;lt;- aggregate(NEIBal$Emissions, 
                             by=list(type=NEIBal$type , year=NEIBal$year), 
                             FUN = sum)

with(totalEmBalTypes, qplot(year, x, 
                            color = type, 
                            geom= c(&amp;quot;point&amp;quot;, &amp;quot;line&amp;quot;), 
                            xlab = &amp;quot;Year&amp;quot;, ylab = &amp;quot;Total PM2.5 Emissions (tons)&amp;quot;, 
                            main = &amp;quot;Evolution of total Emissions in Baltimore by type of source&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/airQuality_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;across-the-united-states-how-have-emissions-from-coal-combustion-related-sources-changed-from-19992008&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Across the United States, how have emissions from coal combustion-related sources changed from 1999–2008?&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;SCCIndex &amp;lt;- as.vector(SCC$SCC[grep(&amp;quot;*comb.*coal&amp;quot;, SCC$Short.Name, ignore.case = TRUE)])

NEICoal &amp;lt;- subset(NEI, SCC %in% SCCIndex)

totalCoal &amp;lt;- with(NEICoal, tapply(Emissions, year, sum, na.rm = TRUE))

plot(names(totalCoal), totalCoal, type =&amp;quot;l&amp;quot;, 
     xlab = &amp;quot;Year&amp;quot;, 
     ylab = &amp;quot;Total Pm2.5 Emissions (tons)&amp;quot;, 
     main = &amp;quot;Total Emission from coal combustion-related sources over the US  &amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/airQuality_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-have-emissions-from-motor-vehicle-sources-changed-from-19992008-in-baltimore-city&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;How have emissions from motor vehicle sources changed from 1999–2008 in Baltimore City?&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NEIBal &amp;lt;- subset(NEI, fips == &amp;quot;24510&amp;quot; &amp;amp; type == &amp;quot;ON-ROAD&amp;quot;)

totalBalMotor &amp;lt;- with(NEIBal, tapply(Emissions, year, sum, na.rm = TRUE))

plot(names(totalBalMotor), totalBalMotor, type =&amp;quot;l&amp;quot;, 
     xlab = &amp;quot;Year&amp;quot;, 
     ylab = &amp;quot;Total Pm2.5 Emissions (tons)&amp;quot;, 
     main = &amp;quot;Total Emission from Motor Vehicles in Baltimore City&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/airQuality_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-emissions-from-motor-vehicle-sources-in-baltimore-city-with-emissions-from-motor-vehicle-sources-in-los-angeles-county-california-fips06037.-which-city-has-seen-greater-changes-over-time-in-motor-vehicle-emissions&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Compare emissions from motor vehicle sources in Baltimore City with emissions from motor vehicle sources in Los Angeles County, California (fips==“06037”). Which city has seen greater changes over time in motor vehicle emissions?&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NEIComp &amp;lt;- subset(NEI, fips %in% c(&amp;quot;24510&amp;quot;, &amp;quot;06037&amp;quot;) &amp;amp; type == &amp;quot;ON-ROAD&amp;quot;)

totalComp &amp;lt;- aggregate(NEIComp$Emissions, 
                       by=list(fips= NEIComp$fips, type=NEIComp$type, year=NEIComp$year), 
                       FUN = sum)

with(totalComp, qplot(year, x, color = fips, geom= c(&amp;quot;point&amp;quot;, &amp;quot;line&amp;quot;), 
                      xlab = &amp;quot;Year&amp;quot;, 
                      ylab = &amp;quot;Total PM2.5 Emissions (tons)&amp;quot;, 
                      main = &amp;quot;Evolution of total Emissions from Motor Vehicles in Baltimore city \n      (fips = 24510) and Los Angeles County (fips = 06037)&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/airQuality_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Individual household electric power consumption</title>
      <link>https://slamara.github.io/project/electricpconsumption/</link>
      <pubDate>Wed, 08 Aug 2018 16:08:18 +0200</pubDate>
      
      <guid>https://slamara.github.io/project/electricpconsumption/</guid>
      <description>&lt;p&gt;The goal of this project is to examine how household energy usage varies over a 2-day period in February, 2007 using the base plotting system. The &lt;a href=&#34;https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip&#34;&gt;data&lt;/a&gt; used in here (in particular, the “Individual household electric power consumption Data Set”) are from the &lt;a href=&#34;http://archive.ics.uci.edu/ml/&#34;&gt;UC Irvine Machine Learning Repository&lt;/a&gt;, a popular repository for machine learning datasets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sqldf)
library(dplyr)
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Estimate the memory usage
paste0(&amp;quot;As the dataset has 2880 rows and 9 columns, it requires about &amp;quot;, 
           round(2880 * 9 * 8 / 2^20, 2), &amp;quot; Megabytes in memory.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;As the dataset has 2880 rows and 9 columns, it requires about 0.2 Megabytes in memory.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Read the data using an SQL statement
sel_data &amp;lt;- read.csv.sql(&amp;quot;./electricPConsumption/household_power_consumption.txt&amp;quot;, 
                            sep = &amp;#39;;&amp;#39;, header = TRUE, 
                            sql=&amp;quot;select * from file where Date in (&amp;#39;1/2/2007&amp;#39;, &amp;#39;2/2/2007&amp;#39;)&amp;quot;)

paste0(&amp;quot;Used memory: &amp;quot;, format(object.size(sel_data), units = &amp;quot;Mb&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Used memory: 0.3 Mb&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create a datetime column given a specific format
sel_data &amp;lt;- sel_data %&amp;gt;% mutate(datetime = as.POSIXct(paste(sel_data$Date, sel_data$Time), 
                                                          format=&amp;quot;%d/%m/%Y %H:%M:%S&amp;quot;))

# Plot the histogram
hist(sel_data$Global_active_power, col = &amp;quot;red&amp;quot;, main = &amp;quot;Global Active Power&amp;quot;, 
         xlab = &amp;quot;Global Active Power (kilowatts)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/electricPConsumption_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create a png file from the histogram
png(file = &amp;quot;plot1.png&amp;quot;, width = 480, height = 480, bg = &amp;quot;transparent&amp;quot;)

hist(sel_data$Global_active_power, col = &amp;quot;red&amp;quot;, main = &amp;quot;Global Active Power&amp;quot;, 
         xlab = &amp;quot;Global Active Power (kilowatts)&amp;quot;)

dev.off()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(sel_data$datetime, sel_data$Global_active_power, type = &amp;quot;l&amp;quot;, xlab = &amp;quot;&amp;quot;, 
         ylab = &amp;quot;Global Active Power (kilowatts)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/electricPConsumption_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow = c(2, 2))

plot(sel_data$datetime, sel_data$Global_active_power, type = &amp;quot;l&amp;quot;, xlab = &amp;quot;&amp;quot;, 
         ylab = &amp;quot;Global Active Power&amp;quot;)

plot(sel_data$datetime, sel_data$Voltage, type = &amp;quot;l&amp;quot;, xlab = &amp;quot;datetime&amp;quot;, 
         ylab = &amp;quot;Voltage&amp;quot;)

plot(sel_data$datetime, sel_data$Sub_metering_1, type = &amp;quot;l&amp;quot;, 
         ylim = range(sel_data$Sub_metering_1), xlab = &amp;quot;&amp;quot;, ylab= &amp;quot;Energy sub metering&amp;quot;)

par(new = TRUE)

plot(sel_data$datetime, sel_data$Sub_metering_2, type = &amp;quot;l&amp;quot;, 
         ylim = range(sel_data$Sub_metering_1), col = &amp;quot;red&amp;quot;, 
         xaxt = &amp;quot;n&amp;quot;, yaxt = &amp;quot;n&amp;quot;, xlab = &amp;quot;&amp;quot;, ylab= &amp;quot;&amp;quot;)

par(new = TRUE)

plot(sel_data$datetime, sel_data$Sub_metering_3, type = &amp;quot;l&amp;quot;, 
         ylim = range(sel_data$Sub_metering_1), col = &amp;quot;blue&amp;quot;, 
         xaxt = &amp;quot;n&amp;quot;, yaxt = &amp;quot;n&amp;quot;, xlab = &amp;quot;&amp;quot;, ylab= &amp;quot;&amp;quot;)

legend(&amp;quot;topright&amp;quot;,legend=c(&amp;quot;Sub_metering_1&amp;quot;, &amp;quot;Sub_metering_2&amp;quot;, &amp;quot;Sub_metering_3&amp;quot;), 
           bty = &amp;quot;n&amp;quot;, lty = c(1,1),col=c(&amp;quot;black&amp;quot;, &amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;))

plot(sel_data$datetime, sel_data$Global_reactive_power, type = &amp;quot;l&amp;quot;, 
         xlab = &amp;quot;datetime&amp;quot;, ylab = &amp;quot;Global_reactive_power&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://slamara.github.io/project/electricPConsumption_files/figure-html/unnamed-chunk-4-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting and cleaning data</title>
      <link>https://slamara.github.io/project/gcd/</link>
      <pubDate>Fri, 03 Aug 2018 18:05:56 +0200</pubDate>
      
      <guid>https://slamara.github.io/project/gcd/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The purpose of this project is to show the ability to collect, work with, and clean a data set. The goal is to prepare tidy data that can be used for later analysis.&lt;/p&gt;
&lt;p&gt;The data used in this project represent data collected from the accelerometers of Samsung Galaxy S smartphones. For a full description please visit the following website:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones&#34; class=&#34;uri&#34;&gt;http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones&lt;/a&gt; &lt;sup&gt;&lt;a href=&#34;#myfootnote1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Here are the data for the project:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip&#34;&gt;https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The script does the following:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Load the libraries &lt;em&gt;data.table&lt;/em&gt; and &lt;em&gt;dplyr&lt;/em&gt; needed to run the script&lt;/li&gt;
&lt;li&gt;Read the files &lt;em&gt;subject_test.txt&lt;/em&gt;, &lt;em&gt;y_test.txt&lt;/em&gt;, &lt;em&gt;X_test.txt&lt;/em&gt; contained in folder &lt;strong&gt;test&lt;/strong&gt; as well as the files &lt;em&gt;subject_train.txt&lt;/em&gt;, &lt;em&gt;y_train.txt&lt;/em&gt;, &lt;em&gt;X_train.txt&lt;/em&gt; in folder &lt;strong&gt;train&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Extract features and activity names to Label the data sets with descriptive variable names&lt;/li&gt;
&lt;li&gt;Merge the training and the tests sets to create one data set&lt;/li&gt;
&lt;li&gt;Coerce the column names to obtain syntactically valid ones&lt;/li&gt;
&lt;li&gt;Extract only the measurements on the mean and standard deviation for each measurement (&lt;strong&gt;sel_data&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Use descriptive activity names to name the activities in the selected data set&lt;/li&gt;
&lt;li&gt;Create a second independent tidy data set with the average of each variable for each activity and each subject (&lt;strong&gt;mean_data&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Create the output files &lt;em&gt;sel_data.csv&lt;/em&gt; and &lt;em&gt;mean_data.csv&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Re-initialize the Global Environment.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load libraries

library(data.table)
library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Read Dataset

subject_test &amp;lt;- fread(&amp;quot;./gcd/subject_test.txt&amp;quot;)
y_test &amp;lt;- fread(&amp;quot;./gcd/y_test.txt&amp;quot;)
x_test &amp;lt;- fread(&amp;quot;./gcd/X_test.txt&amp;quot;)

subject_train &amp;lt;- fread(&amp;quot;./gcd/subject_train.txt&amp;quot;)
y_train &amp;lt;- fread(&amp;quot;./gcd/y_train.txt&amp;quot;)
x_train &amp;lt;- fread(&amp;quot;./gcd/X_train.txt&amp;quot;)

# Extract features and activity names

cnames &amp;lt;- fread(&amp;quot;./gcd/features.txt&amp;quot;)

lActivities &amp;lt;- fread(&amp;quot;./gcd/activity_labels.txt&amp;quot;)

# Label the data sets with descriptive variable names

colnames(y_test) &amp;lt;- &amp;quot;activity&amp;quot;
colnames(subject_test) &amp;lt;- &amp;quot;subject&amp;quot;
colnames(x_test) &amp;lt;- as.character(cnames$V2)
all_test &amp;lt;- cbind(subject_test, y_test, x_test)

colnames(y_train) &amp;lt;- &amp;quot;activity&amp;quot;
colnames(subject_train) &amp;lt;- &amp;quot;subject&amp;quot;
colnames(x_train) &amp;lt;- as.character(cnames$V2)
all_train &amp;lt;- cbind(subject_train, y_train, x_train)


# Merge the training and the tests sets to create one data set

all_data &amp;lt;- rbind(all_test, all_train)
paste0(&amp;quot;Number of variables: &amp;quot;, dim(all_data)[2])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Number of variables: 563&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paste0(&amp;quot;Number of Observations: &amp;quot;, dim(all_data)[1])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Number of Observations: 10299&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Coerce column names to obtain syntactically valid ones

valid_names &amp;lt;- make.names(names=names(all_data), unique=TRUE, allow_ = TRUE)
names(all_data) &amp;lt;- valid_names

# Extract only the measurements on the mean and standard deviation for each measurement

sel_data &amp;lt;- select(all_data, matches(&amp;quot;subject|activity|\\.mean\\.|\\.std\\.&amp;quot;))

names(sel_data) &amp;lt;- gsub(names(sel_data), pattern = &amp;quot;\\.\\.&amp;quot;, replacement = &amp;quot;&amp;quot;)

# Use descriptive activity names to name the activities in the selected data set

sel_data$activity &amp;lt;- lActivities$V2[match(sel_data$activity, lActivities$V1)]

paste0(&amp;quot;The recorded activities are: &amp;quot;, paste(unique(sel_data$activity), collapse = &amp;quot;, &amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;The recorded activities are: STANDING, SITTING, LAYING, WALKING, WALKING_DOWNSTAIRS, WALKING_UPSTAIRS&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;write.table(sel_data, file = &amp;quot;./gcd/sel_data.txt&amp;quot;, row.names = FALSE)

# From the previous data set, create a second independent tidy data set with the average
# of each variable for each activity and each subject

mean_data &amp;lt;- sel_data %&amp;gt;% group_by(subject, activity) %&amp;gt;% summarise_all(funs(mean))

write.table(mean_data, file = &amp;quot;./gcd/mean_data.txt&amp;quot;, row.names = FALSE)

# Re-initialize the Global Environment

rm(list = ls())&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;reference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reference&lt;/h3&gt;
&lt;p&gt;&lt;a name=&#34;myfootnote1&#34;&gt;[1]&lt;/a&gt;: Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Ranking US Hospitals</title>
      <link>https://slamara.github.io/project/rankingushospitals/</link>
      <pubDate>Fri, 03 Aug 2018 18:05:56 +0200</pubDate>
      
      <guid>https://slamara.github.io/project/rankingushospitals/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The purpose of this project is to rank over 4000 US hospitals according to the quality of care. The data represent a small subset of the data available at the Hospital Compare web site (&lt;a href=&#34;http://hospitalcompare.hhs.gov&#34; class=&#34;uri&#34;&gt;http://hospitalcompare.hhs.gov&lt;/a&gt;) run by the U.S. Department of Health and Human Services.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://d396qusza40orc.cloudfront.net/rprog%2Fdata%2FProgAssignment3-data.zip&#34;&gt;zip file&lt;/a&gt; for this project contains three files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;outcome-of-care-measures.csv&lt;/strong&gt;: Contains information about 30-day mortality and readmission rates for heart attacks, heart failure, and pneumonia for over 4,000 hospitals.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hospital-data.csv&lt;/strong&gt;: Contains information about each hospital.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hospital_Revised_Flatfiles.pdf&lt;/strong&gt;: Descriptions of the variables in each file (i.e the code book). This document contains information about many other files that are not included with this project. We want to focus on the variables for Number 19 (“Outcome of Care Measures.csv”) and Number 11 (“Hospital Data.csv”).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;finding-the-best-hospital-in-a-state&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Finding the best hospital in a state&lt;/h2&gt;
&lt;p&gt;I write a function called &lt;strong&gt;best&lt;/strong&gt; which takes two arguments: the 2-character abbreviated name of a state and an outcome name. The function returns a character vector with the name of the hospital that has the lowest 30-day mortality for the specified outcome in that state. The outcomes can be one of “heart attack”, “heart failure”, or “pneumonia”. The Hospitals that do not have data on a particular outcome are excluded from the set of hospitals when deciding the rankings.&lt;/p&gt;
&lt;p&gt;If there is a tie for the best hospital for a given outcome, then the hospital names should be sorted in alphabetical order and the first hospital in that set should be chosen.&lt;/p&gt;
&lt;p&gt;The function checks the validity of its arguments and throws an error via the stop function with the message “invalid state” or “invalid outcome” when an invalid state resp. outcome value is passed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best &amp;lt;- function(state, outcome) {
## Read outcome data

    data &amp;lt;- read.csv(&amp;quot;./rankingUsHospitals/outcome-of-care-measures.csv&amp;quot;, 
                         colClasses = &amp;quot;character&amp;quot;)

## Check that state and outcome are valid

    if (!(state %in% data$State)) {
        result &amp;lt;- &amp;quot;invalid state&amp;quot;
      }
    else if (!outcome %in% c(&amp;quot;heart attack&amp;quot;, &amp;quot;heart failure&amp;quot;, &amp;quot;pneumonia&amp;quot;)) {
        result &amp;lt;- &amp;quot;invalid outcome&amp;quot;
      }
    else{
        keys &amp;lt;- c(&amp;quot;heart attack&amp;quot; = 11, &amp;quot;heart failure&amp;quot; = 17, &amp;quot;pneumonia&amp;quot; = 23)
        outcomeKey &amp;lt;- keys[outcome]
  
## Return hospital name in that state with lowest 30-day death rate
  
        dataPerState &amp;lt;- split(data, data$State)
        dataOurState &amp;lt;- dataPerState[[state]]
        dataOurState &amp;lt;- dataOurState[ order(dataOurState[&amp;quot;Hospital.Name&amp;quot;]), ]
        dataOutcome &amp;lt;- suppressWarnings(as.numeric(dataOurState[, outcomeKey]))
        good &amp;lt;- complete.cases(dataOutcome)
        dataOutcome &amp;lt;- dataOutcome[good]
        dataOurState &amp;lt;- dataOurState[good,]
        minimum &amp;lt;- min(dataOutcome)
        index &amp;lt;- match(minimum, dataOutcome)
        result &amp;lt;- dataOurState[index, 2]
    }
    result
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;testing-best&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Testing &lt;strong&gt;best&lt;/strong&gt;:&lt;/h3&gt;
&lt;p&gt;A set of state names and outcomes is used to check the function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;chk1 &amp;lt;- c(&amp;quot;TX&amp;quot;, &amp;quot;heart attack&amp;quot;)
chk2 &amp;lt;- c(&amp;quot;TX&amp;quot;, &amp;quot;heart failure&amp;quot;)
chk3 &amp;lt;- c(&amp;quot;MD&amp;quot;, &amp;quot;heart attack&amp;quot;)
chk4 &amp;lt;- c(&amp;quot;MD&amp;quot;, &amp;quot;pneumonia&amp;quot;)
chk5 &amp;lt;- c(&amp;quot;BB&amp;quot;, &amp;quot;heart attack&amp;quot;)
chk6 &amp;lt;- c(&amp;quot;NY&amp;quot;, &amp;quot;hert attack&amp;quot;)
dat &amp;lt;- data.table(chk1, chk2, chk3, chk4, chk5, chk6)
dat &amp;lt;- t(dat)
as.list(apply(dat, 1, function(x){do.call(best, as.list(x))}))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $chk1
## [1] &amp;quot;CYPRESS FAIRBANKS MEDICAL CENTER&amp;quot;
## 
## $chk2
## [1] &amp;quot;FORT DUNCAN MEDICAL CENTER&amp;quot;
## 
## $chk3
## [1] &amp;quot;JOHNS HOPKINS HOSPITAL, THE&amp;quot;
## 
## $chk4
## [1] &amp;quot;GREATER BALTIMORE MEDICAL CENTER&amp;quot;
## 
## $chk5
## [1] &amp;quot;invalid state&amp;quot;
## 
## $chk6
## [1] &amp;quot;invalid outcome&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ranking-hospitals-by-outcome-in-a-state&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Ranking hospitals by outcome in a state&lt;/h2&gt;
&lt;p&gt;To this intent, I write a function &lt;strong&gt;rankHospital&lt;/strong&gt; which takes three arguments: the 2-character abbreviated name of a state (state), an outcome (outcome), and the ranking of a hospital in that state for that outcome (num).&lt;/p&gt;
&lt;p&gt;The function returns a character vector with the name of the hospital that has the ranking specified by the &lt;strong&gt;num&lt;/strong&gt; argument. The &lt;strong&gt;num&lt;/strong&gt; argument can take the values “best”, “worst”, or an integer indicating the ranking.&lt;/p&gt;
&lt;p&gt;The Hospitals that do not have data on a particular outcome are excluded from the set of hospitals when deciding the rankings. Also, If the number given by num is larger than the number of hospitals in that state, then the function returns NA.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rankHospital &amp;lt;- function(state, outcome, num = &amp;quot;best&amp;quot;) {
    
  
## Read outcome data

    data &amp;lt;- read.csv(&amp;quot;./rankingUsHospitals/outcome-of-care-measures.csv&amp;quot;, 
                         colClasses = &amp;quot;character&amp;quot;)

## Check that state and outcome are valid

    if (!(state %in% data$State)) {
        result &amp;lt;- &amp;quot;invalid state&amp;quot;
    }
    else if (!outcome %in% c(&amp;quot;heart attack&amp;quot;, &amp;quot;heart failure&amp;quot;, &amp;quot;pneumonia&amp;quot;)) {
        result &amp;lt;- &amp;quot;invalid outcome&amp;quot;
    }
    else {
        keys &amp;lt;- c(&amp;quot;heart attack&amp;quot; = 11, &amp;quot;heart failure&amp;quot; = 17, &amp;quot;pneumonia&amp;quot; = 23)
        outcomeKey &amp;lt;- keys[outcome]
  
  
## Return hospital name in that state with the given rank
## 30-day death rate
  
        dataPerState &amp;lt;- split(data, data$State)
        dataOurState &amp;lt;- dataPerState[[state]]
        dataOutcome &amp;lt;- suppressWarnings(as.numeric(dataOurState[, outcomeKey]))
        good &amp;lt;- complete.cases(dataOutcome)
        dataOutcome &amp;lt;- dataOutcome[good]
        dataOurState &amp;lt;- dataOurState[good,]
        dataOurState &amp;lt;- dataOurState[order(dataOutcome, dataOurState[&amp;quot;Hospital.Name&amp;quot;]),]
        if (grepl(&amp;quot;^[0-9]+$&amp;quot;, num)) {
            if (as.numeric(num) &amp;gt; length(dataOutcome)) {
                result &amp;lt;- NA
            }
            else {
                result &amp;lt;- dataOurState[as.numeric(num), &amp;quot;Hospital.Name&amp;quot;]
            }
        }    
        else if (num == &amp;quot;best&amp;quot;) {
                result &amp;lt;- dataOurState[1, &amp;quot;Hospital.Name&amp;quot;]
        }
        else if (num == &amp;quot;worst&amp;quot;) {
                result &amp;lt;- dataOurState[length(dataOutcome), &amp;quot;Hospital.Name&amp;quot;]
        }
        else result &amp;lt;- NA
    }
    result
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;testing-rankhospital&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Testing &lt;strong&gt;rankHospital&lt;/strong&gt;&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;chk1 &amp;lt;- c(&amp;quot;TX&amp;quot;, &amp;quot;heart failure&amp;quot;, 4)
chk2 &amp;lt;- c(&amp;quot;MD&amp;quot;, &amp;quot;heart attack&amp;quot;, &amp;quot;worst&amp;quot;)
chk3 &amp;lt;- c(&amp;quot;MN&amp;quot;, &amp;quot;heart attack&amp;quot;, 5000)
dat &amp;lt;- data.table(chk1, chk2, chk3)
dat &amp;lt;- t(dat)
as.list(apply(dat, 1, function(x){do.call(rankHospital, as.list(x))}))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $chk1
## [1] &amp;quot;DETAR HOSPITAL NAVARRO&amp;quot;
## 
## $chk2
## [1] &amp;quot;HARFORD MEMORIAL HOSPITAL&amp;quot;
## 
## $chk3
## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ranking-hospitals-in-all-states&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Ranking hospitals in all states&lt;/h2&gt;
&lt;p&gt;I implement a function &lt;strong&gt;rankAll&lt;/strong&gt; which takes as arguments the outcome name (outcome) and hospital ranking (num) and returns a 2-column data frame containing the hospital in each state that has the ranking specified in num.&lt;/p&gt;
&lt;p&gt;The function returns a value for every state (some may be NA). The first column in the data frame contains the hospital name and the second one contains the 2-character abbreviation for the state name. Hospitals that do not have data on a particular outcome are excluded from the set of hospitals when deciding the rankings.&lt;/p&gt;
&lt;p&gt;Although it is possible to call the &lt;strong&gt;rankHospital&lt;/strong&gt; function from the previous section, I decided, for didactic purposes, not using it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rankAll &amp;lt;- function(outcome, num = &amp;quot;best&amp;quot;) {

    dataAll &amp;lt;- data.frame(hospital = character(), state = character())
  
## Read outcome data

    data &amp;lt;- read.csv(&amp;quot;./rankingUsHospitals/outcome-of-care-measures.csv&amp;quot;, 
                         colClasses = &amp;quot;character&amp;quot;)
  
## Check that outcome and num are valid

    if (!outcome %in% c(&amp;quot;heart attack&amp;quot;, &amp;quot;heart failure&amp;quot;, &amp;quot;pneumonia&amp;quot;)) {
        dataAll &amp;lt;- &amp;quot;invalid outcome&amp;quot;
    }
    else {
        keys &amp;lt;- c(&amp;quot;heart attack&amp;quot; = 11, &amp;quot;heart failure&amp;quot; = 17, &amp;quot;pneumonia&amp;quot; = 23)
        outcomeKey &amp;lt;- keys[outcome]

## For each state, find the hospital of the given rank

        dataPerState &amp;lt;- split(data, data$State)
        for (stat in names(dataPerState)) {
        dataOurState &amp;lt;- dataPerState[[stat]]
        dataOutcome &amp;lt;- suppressWarnings(as.numeric(dataOurState[, outcomeKey]))
        good &amp;lt;- complete.cases(dataOutcome)
        dataOutcome &amp;lt;- dataOutcome[good]
        dataOurState &amp;lt;- dataOurState[good,]
        dataOurState &amp;lt;- dataOurState[ order(dataOutcome, dataOurState[&amp;quot;Hospital.Name&amp;quot;]), ]
        
        if (num == &amp;quot;best&amp;quot;) {
            numState &amp;lt;- c(1)
        } else {
            if (num == &amp;quot;worst&amp;quot;) {
                numState &amp;lt;- length(dataOutcome)
            } else {
                numState &amp;lt;- num
            }
        }
    
        dataPart &amp;lt;- data.frame(hospital = dataOurState[numState, &amp;quot;Hospital.Name&amp;quot;], 
                                   state = stat, row.names = stat)
        
        dataAll &amp;lt;- rbind(dataAll, dataPart)
        }
    }

## Return a data frame with the hospital names and the (abbreviated) state name

    dataAll
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;testing-rankall&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Testing &lt;strong&gt;rankAll&lt;/strong&gt;&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(rankAll(&amp;quot;heart attack&amp;quot;, 20), 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                               hospital state
## AK                                &amp;lt;NA&amp;gt;    AK
## AL      D W MCMILLAN MEMORIAL HOSPITAL    AL
## AR   ARKANSAS METHODIST MEDICAL CENTER    AR
## AZ JOHN C LINCOLN DEER VALLEY HOSPITAL    AZ
## CA               SHERMAN OAKS HOSPITAL    CA
## CO            SKY RIDGE MEDICAL CENTER    CO
## CT             MIDSTATE MEDICAL CENTER    CT
## DC                                &amp;lt;NA&amp;gt;    DC
## DE                                &amp;lt;NA&amp;gt;    DE
## FL      SOUTH FLORIDA BAPTIST HOSPITAL    FL&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tail(rankAll(&amp;quot;pneumonia&amp;quot;, &amp;quot;worst&amp;quot;), 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                      hospital state
## WI MAYO CLINIC HEALTH SYSTEM - NORTHLAND, INC    WI
## WV                     PLATEAU MEDICAL CENTER    WV
## WY           NORTH BIG HORN HOSPITAL DISTRICT    WY&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tail(rankAll(&amp;quot;heart failure&amp;quot;), 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                                             hospital state
## TN                         WELLMONT HAWKINS COUNTY MEMORIAL HOSPITAL    TN
## TX                                        FORT DUNCAN MEDICAL CENTER    TX
## UT VA SALT LAKE CITY HEALTHCARE - GEORGE E. WAHLEN VA MEDICAL CENTER    UT
## VA                                          SENTARA POTOMAC HOSPITAL    VA
## VI                            GOV JUAN F LUIS HOSPITAL &amp;amp; MEDICAL CTR    VI
## VT                                              SPRINGFIELD HOSPITAL    VT
## WA                                         HARBORVIEW MEDICAL CENTER    WA
## WI                                    AURORA ST LUKES MEDICAL CENTER    WI
## WV                                         FAIRMONT GENERAL HOSPITAL    WV
## WY                                        CHEYENNE VA MEDICAL CENTER    WY&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>https://slamara.github.io/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0200</pubDate>
      
      <guid>https://slamara.github.io/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
